---
layout: post
title:  "[ML] HunKim`s ML 8"
date:   2017-07-14 01:38:33 +0900
categories: ML
tags: [AI클럽, gitbook, ML, Machine Learning, Deep Learning]

---

# ReLU, Weight 초기화, Dropout, 앙상블, Xavier, Adam
---

![ReLU](http://farm4.static.flickr.com/3434/3942758168_94dac63ff6_z.jpg)

이제 Sigmoid가 아닌 **ReLU** 를 알아보자.

만약 앞서 XOR를 layer를 9단까지 하면 어떻게 될까.

실제로 돌려보면 정확도가 반으로 떨어진다.

왜 그럴까?

그게 바로 `Backpropagation` 때문이다.

2단, 3단정도의 그래프는 잘 학습이 되는데, 많이 늘어나면 정확도가 떨어진다.

그 이유는 `chain rule`로 설명이 되는데, 이전 노드에 항상 1보다 작은 값이 곱해지고 할수록 0에 가까워지므로, 0에 수렴하게 되면서, 결국 입력이 별로 상관이 없어지게 된다.

이 문제 때문에 AI의 2차 winter가 온 것이기도 하다.

그 결과 잘못된 `non-linearity`라고 밝혀졌고, sigmoid가 항상 1보다 작은게 문제라고 나왔다.

따라서 **ReLU(Rectified Linear Unit)** 를 쓰게 되었다.

그러나, 마지막은 sigmoid를 쓰는데, 그 이유는 0~1사이의 값을 주기 위해서다.

그리고 ReLU 말고도 `Leaky ReLU`, `Maxout`, `ELU`등도 있다.

그럼 이제, Weight 초기화를 진행해보자.

항상 Random으로 할 때 보면, 상황에 따라 결과가 다르니, 최적화된 Weight를 알아보는 것이다.

예를 들어, 만약 초기값을 모두 0으로 한다면 GradientDescent는 0이 곱해지며 사라지게 된다.

따라서, 모든 Weight는 0이 되면 안된다.

`DBN`이라는 것을 쓰는데, `Pre-Training`이 필요하다.

여기선 X값만 필요하다.

2개의 layer를 가지고 서로서로 왔다갔다하며 비슷해질 떄까지 학습시킨다.
그리고 그다음 layer... 쭉 해서 마지막 까지 간다. 그때 남아있는 weight가 있을 것이다.

그게 바로 초기화된 weight이다.

근데 이건 조금 옛날 방식이다.

`Xavier/He initialization` 이란 것들이 있다.

`Xavier`방식은 input(fan_in)과 output(fan_out) 수를 이용하는데, weight을 random하게 주는데,

`(fan_in, fan_out)/np.sqrt(fan_in))`을 한 값 사이에서 주는 것이다.

`He`방법은 `(fan_in, fan_out)/np.sqrt(fan_in/2)`를 한 값 사이에서 선택하는 것이다.

그럼 마지막으로 **Dropout** 과 **앙상블** 에 대해 알아보자.

Overfitting이 될 때, `Regularization strength` 라는 방법이 있었다.

이 이외에 **Dropout** 이라는 걸 쓴다.

그만둔다는 뜻인데, 학습 시킨 node를 몇 개 빼는 것이다.

단, 주의할 점은 학습할 때만 그렇게 한다는 것이다.

그럼 **Ensemble(앙상블)** 이 무엇인지 알아보자.

독립적으로 NN을 만들었을 때, Training set을 여러개 만들어서 학습시킬 텐데,

같은 형태로 DeepLearning 모델을 여러개 만든다. 그런데 초기값이 다르니 조금씩 다를것이고 이걸 합쳐 답을 내는 것이다.

NN은 이제 레고처럼 쌓아가면 된다.

Layer는 우리가 정해서 쓰면 된다.

근데 방법이 여러가지다.

`Fast forward`의 경우, 중간에 몇개를 건너 뛰고, 진행하는 것을 말한다.

`Split & merge` 방법도 있다. 말 그대로, 시작부터, 혹은 중간부터 나눠서 진행하다가 합치고 싶을 때에 합치고 진행하거나 다시 나누는 등으로 진행하는 방법이다.

`Recurrent Neural Network`는 지금까지 앞으로만 진행했는데, 옆으로도 나가보자라는 생각을 한 것이다.

네트워크는 어떤 형태든, 좋은 결과가 나오는 것으로 만들어 내면 된다.

즉, 상상력을 동원해 이 레고 블럭을 사용해 보면 된다.

그럼 이번에는 `NN, ReLU, Xavier, Dropout, Adam`을 한번 구현해 보도록 하자.


    import tensorflow as tf
    from tensorflow.examples.tutorials.mnist import input_data

    mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)

    learning_rate = 0.001
    batch_size = 100
    training_epochs = 15
    nb_classes = 10

    X = tf.placeholder(tf.float32, [None, 784])
    # 0 - 9 digits recognition = 10 classes
    Y = tf.placeholder(tf.float32, [None, nb_classes])

    W  = tf.Variable(tf.random_normal([784, 10]))
    b = tf.Variable(tf.random_normal([10]))
    hypothesis = tf.matmul(X, W) + b

    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))
    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)

    sess = tf.Session()
    sess.run(tf.global_variables_initializer())

    for epoch in range(training_epochs):
        avg_cost = 0
        total_batch = int(mnist.train.num_examples / batch_size)

        for i in range(total_batch):
            batch_xs, batch_ys = mnist.train.next_batch(batch_size)
            feed_dict = {X: batch_xs, Y: batch_ys}
            c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)
            avg_cost += c / total_batch

        print('Epoch:', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))
    print('Learning Finished')

    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    print('Accuracy: ', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))

위와 같은 코드를 돌려보면 정확도가 약 90% 정도가 나온다. softmax만을 이용한 분류이기 때문이다.

좀 더 개선해보자.

    X = tf.placeholder(tf.float32, [None, 784])
    Y = tf.placeholder(tf.float32, [None, nb_classes])

    W1  = tf.Variable(tf.random_normal([784, 256]))
    b1 = tf.Variable(tf.random_normal([256]))
    L1 = tf.nn.relu(tf.matmul(X, W1) + b1)

    W2  = tf.Variable(tf.random_normal([256, 256]))
    b2 = tf.Variable(tf.random_normal([256]))
    L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)

    W3  = tf.Variable(tf.random_normal([256, 10]))
    b3 = tf.Variable(tf.random_normal([10]))

    hypothesis = tf.matmul(L2, W3) + b3

    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))
    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)


이번에 Layer를 늘리고, relu 함수를 사용했다.

그럼 이제 weight를 초기화 하는 방법인 `Xavier initialization`을 진행해보자.

    W1 = tf.get_variable("W1", shape=[784, 256], initializer=tf.contrib.layers.xavier_initializer())
    b1 = tf.Variable(tf.random_normal([256]))
    L1 = tf.nn.relu(tf.matmul(X, W1) + b1)

    W2 = tf.get_variable("W2", shape=[256, 256], initializer=tf.contrib.layers.xavier_initializer())
    b2 = tf.Variable(tf.random_normal([256]))
    L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)

    W3 = tf.get_variable("W3", shape=[256, 10], initializer=tf.contrib.layers.xavier_initializer())
    b3 = tf.Variable(tf.random_normal([10]))

크게 바뀐 것은 없지만 정확도는 98%정도가 된다.

초기값에 따라 얼마나 효과가 커지는 지 알 수 있다. 특히, 처음부터 아마 cost가 0.3 정도로 매우 낮게 형성됨을 볼 수 있다.

그럼 더욱 잘되게 만들어 보자.


    W1 = tf.get_variable("W1", shape=[784, 512], initializer=tf.contrib.layers.xavier_initializer())
    b1 = tf.Variable(tf.random_normal([512]))
    L1 = tf.nn.relu(tf.matmul(X, W1) + b1)

    W2 = tf.get_variable("W2", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())
    b2 = tf.Variable(tf.random_normal([512]))
    L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)

    W3 = tf.get_variable("W3", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())
    b3 = tf.Variable(tf.random_normal([512]))
    L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)

    W4 = tf.get_variable("W4", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())
    b4 = tf.Variable(tf.random_normal([512]))
    L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)

    W5 = tf.get_variable("W5", shape=[512, 10], initializer=tf.contrib.layers.xavier_initializer())
    b5 = tf.Variable(tf.random_normal([10]))
    hypothesis = tf.matmul(L4, W5) + b5

Layer를 늘려보았다.

아마 조금 실망스럽게도 정확도가 97%로 떨어진다.

아마 Overfitting의 문제일 것이다.

그럼 `Dropout`을 해서 해결해보자.

    import tensorflow as tf
    from tensorflow.examples.tutorials.mnist import input_data

    mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)

    learning_rate = 0.001
    batch_size = 100
    training_epochs = 15
    nb_classes = 10


    X = tf.placeholder(tf.float32, [None, 784])
    Y = tf.placeholder(tf.float32, [None, nb_classes])
    keep_prob = tf.placeholder(tf.float32)

    W1 = tf.get_variable("W1", shape=[784, 512], initializer=tf.contrib.layers.xavier_initializer())
    b1 = tf.Variable(tf.random_normal([512]))
    L1 = tf.nn.relu(tf.matmul(X, W1) + b1)
    L1 = tf.nn.dropout(L1, keep_prob=keep_prob)

    W2 = tf.get_variable("W2", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())
    b2 = tf.Variable(tf.random_normal([512]))
    L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)
    L2 = tf.nn.dropout(L2, keep_prob=keep_prob)

    W3 = tf.get_variable("W3", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())
    b3 = tf.Variable(tf.random_normal([512]))
    L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)
    L3 = tf.nn.dropout(L3, keep_prob=keep_prob)

    W4 = tf.get_variable("W4", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())
    b4 = tf.Variable(tf.random_normal([512]))
    L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)
    L4 = tf.nn.dropout(L4, keep_prob=keep_prob)

    W5 = tf.get_variable("W5", shape=[512, 10], initializer=tf.contrib.layers.xavier_initializer())
    b5 = tf.Variable(tf.random_normal([10]))
    hypothesis = tf.matmul(L4, W5) + b5

    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))
    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)

    sess = tf.Session()
    sess.run(tf.global_variables_initializer())

    for epoch in range(training_epochs):
        avg_cost = 0
        total_batch = int(mnist.train.num_examples / batch_size)

        for i in range(total_batch):
            batch_xs, batch_ys = mnist.train.next_batch(batch_size)
            feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}
            c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)
            avg_cost += c / total_batch

        print('Epoch:', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))
    print('Learning Finished')

    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    print('Accuracy: ', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))

보통 learning 단계에선 0.5 ~ 0.7개의 노드를 사용하고, test시에는 모든 노드를 다 쓰기 때문에, placeholder로 적용한 `keep_prob`를 이용해, 위와 같이 구현한다.

그리고 위 코드에서 계속

`optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)`

로 **Adam** 이라는 것을 사용해 왔다.

이전에는 GradientDescent 를 사용했었지만, 굉장히 많은 optimizer가 있으니 하나씩 구현해 보면 좋다.

그리고 Batch Normalization 이라는 것이 있으니 98%를 넘길 수 있는지 한번 보도록 하면 좋다.

다음엔 `CNN`을 사용해서 보도록 하자.
