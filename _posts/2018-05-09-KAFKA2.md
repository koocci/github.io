---
layout: post
title:  "[KAFKA] KAFKA 2"
date:   2018-05-09 15:46:00 +0900
categories: KAFKA
tags: [Logging, Kafka, FluentD]

---

## Kafka 면접 질문
---


![KAFKA](http://farm4.static.flickr.com/3101/2768292353_72361d854a_z.jpg)

일단, 가장 많이 받은 것은 무엇으로 로깅처리를 구현하였나 라는 질문이다.
나의 경우, Kafka와 FluentD를 이용해 로깅을 처리 했기 때문에, 이것에 대해 좀 자세히 알아둘 필요가 있었다.

앞서, 문서 해석을 통해 Kafka에 대한 성격은 알아볼 수 있었다. 기본적인 사항만 요약을 해보자면, `Distributed Streaming Platform` 분산형 스트리밍 플랫폼이며, **결함감내** 의 내구성 방식으로 레코드의 스트림을 저장하고, 레코드 스트림이 발생하면 처리하는 Event Driven의 성격을 가지고 있다. 또한, 무엇보다 기존의 메시지 시스템의 큰 모델이었던, **Queue** 방식과 **publish-subscribe** 방식 두가지를 다 가능하도록 만들었다는 것이 장점이다.

잠깐 이부분을 정리하자면,

|      |                                      Queue                                      |                           Publish-Subscribe                          |
|:----:|:-------------------------------------------------------------------------------:|:--------------------------------------------------------------------:|
| 설명 |     Consumer 풀은 서버에서 읽을 수 있으며 각 레코드는 그 중 하나에 저장한다     |             레코드는 모든 Consumer에게 브로드캐스트 한다             |
| 장점 | 여러 Consumer 인스턴스에서 데이터 처리를 분할할 수 있으므로 처리 규모 확장 가능 |           여러 프로세스에 데이터를 브로드 캐스트 할 수 있다          |
| 단점 |       다중 subscriber가 아니므로, 한번 한 프로세스가 읽은 데이터는 사라짐       | 모든 메시지가 모든 Consumer에게 전달되므로 처리를 조정할 방법이 없다 |


그러나, Kafka는 이 두 개념의 장점을 **Consumer 그룹** 을 이용해 들고왔는데, queue에서와 마찬가지로 Consumer 그룹은 프로세스 모음(Consumer 그룹의 구성원)을 통해 처리를 나눌 수 있고, publish-subscribe처럼 여러 Consumer 그룹에 메세지를 브로드 캐스트 할 수 있다.

게다가 순서에서도 효율이 높은데, Queue의 경우 병렬 처리의 개념이 없어, 서버에서 순차적으로 레코드를 가지고 있다가 여러 Consumer가 큐에서 Consume하려 할 때, 순차적으로 보내주더라도 레코드가 비동기적으로 전달되기 때문에 순서성이 사라진다. (물론, 각각 단일 Queue를 붙이면 가능하지만, 효율이 떨어질 수 밖에 없다)

그러나, Kafka는 TOPIC 내에서 파티션을 이용해 순서 보증과 로드 밸런싱을 모두 제공 할 수 있다.
즉, 파티션 하나를 Consumer 그룹의 Consumer에게 할당하면서, 각각 개별적으로 Consume 될 수 있게 만든 것이다.

다만, Consumer 그룹에서 파티션보다 많은 수의 Consumer를 가질 수가 없다.


또한, 파일로 저장된다는 것도 기억하자.

이렇게 Kafka가 정리되었고, **FluentD** 에 대해 알아보자.

---

### FluentD

---

`Fluentd is an open source data collector for unified logging layer`

FluentD는 통합 로깅 계층을 위한 오픈 소스 데이터 수집기이다.

FluentD의 [홈페이지](https://www.fluentd.org/)에 들어가면 첫 문구이다.

즉, 말 그대로 데이터 수집기다.

또한, 이 성격으로는 다음과 같이 볼 수 있다고 한다.

아키텍쳐의 단순성과 이를 기반으로 한 안정성을 초점을 두고 있다. 그래서 아키텍쳐 구성이나 설정이 간단하다.

출처: [http://bcho.tistory.com/1115](http://bcho.tistory.com/1115) [조대협의 블로그]

즉, 나의 경우 FluentD만으로도 로그를 수집해 저장할 수 있지만, 하나의 Producer로써 사용하였다.

FluentD의 Chunk개념을 이용해, 각기 다른 레벨의 로그를 수집하고, 각각을 Producer로써 Kafka에 제공한 뒤, HTTP Client, DB Client로 Consumer를 만들고 DB에 저장하거나, 웹으로 보일 수 있게 만들었다.

해당사항에 대해서는 내가 했었던 [Mini_Clova](https://github.com/koocci/miniClova)
내의 pdf에 나와 있다.

**Zookeeper** 라는 것도 Kafka를 사용할 떄 사용하게 되는데, 카프카의 노드 관리를 해주고, Topic의 offset 정보등을 저장하기 위해 필요하다.

출처: [https://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-%EC%B2%98%EC%9D%8C-%EC%A0%91%ED%95%98%EB%8A%94-kafka/](https://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-%EC%B2%98%EC%9D%8C-%EC%A0%91%ED%95%98%EB%8A%94-kafka/) [Kafka 운영자가 말하는 처음 접하는 Kafka]


---

###  카프카가 왜 분산처리에 좋은가?

---

해당 질문은 앞서 이미 설명한 듯하다.
말 그대로 카프카가 분산형 스트리밍 플랫폼이다.

Queue와 Publish-Subscribe 모델의 장점을 가져온 Kafka는 Consumer 개념을 이용해, 브로드캐스팅 처리와 각 개별적인 병렬 처리도 가능하게 한다.

---

### 카프카를 사용하다가 죽으면 어떻게 되냐?

---

사실 가장 알고 싶었던 개념이다.

Partition의 경우, 하나의 Leader를 가지고 있고, Leader중 하나가 죽었을 경우, Follower중 하나가 Leader가 되는 형태가 된다.
Leader가 입출력을 처리한다면, Follower는 단순히 Leader의 복제본이다.

그러나, Kafka가 죽는다면 이라는 질문이 Partition을 의미했던 것인지 알기가 힘들다. 따라서 이리저리 알아보려 했다.

가장 핵심적인 설명은 [Kafka 운영자가 말하는 Topic Replication](https://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-topic-replication/) 여기서 볼 수 있었다.

앞서, 설명한 것과 같이 Partition의 경우가 아닌, ALL DOWN의 경우를 설명해 두었다.

즉, 더이상 Leader가 될 수 있는 Replica가 없는 경우, Read/Write가 멈추는 것은 당연하다. 다만, 복구될 때 대응 방법이 나눠어 진다.

1. 마지막까지 leader였던 broker1번이 up이 되고 다시 leader가 될 때까지 기다린다.(모든 데이터를 가지고 있을 가능성이 높다)
2. ISR과 상관없이 누구라도 가장 빨리 up이 되는 topic이 leader가 된다.(데이터 손실이 되더라도 장애 대응이 빠르다)

다음과 같다.

이로써 두번에 걸친 Kafka에 대한 설명은 끝이 났다.

다음에는 Node js와 Javascript 쪽에 대한 면접 질문에 대해 적어보겠다.
